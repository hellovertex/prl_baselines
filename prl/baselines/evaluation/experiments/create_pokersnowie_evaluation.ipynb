{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Type, Tuple, Any\n",
    "\n",
    "import os\n",
    "import gin\n",
    "gin.enter_interactive_mode()\n",
    "import gym\n",
    "from prl.environment.Wrappers.augment import AugmentObservationWrapper\n",
    "from prl.environment.Wrappers.utils import init_wrapped_env\n",
    "\n",
    "from prl.baselines.agents.agents import CallingStation, StakePlayerImitator\n",
    "from prl.baselines.agents.core.base_agent import RllibAgent\n",
    "from prl.baselines.evaluation.core.experiment import PokerExperiment, PokerExperimentParticipant\n",
    "from prl.baselines.evaluation.pokersnowie.export import PokerExperimentToPokerSnowie\n",
    "\n",
    "\n",
    "AGENT_CLS = Type[RllibAgent]\n",
    "POLICY_CONFIG = Dict[str, Any]\n",
    "STARTING_STACK = int\n",
    "AGENT_INIT_COMPONENTS = Tuple[AGENT_CLS, POLICY_CONFIG, STARTING_STACK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def make_participants(agent_init_components: List[AGENT_INIT_COMPONENTS],\n",
    "                      observation_space: gym.Space,\n",
    "                      action_space: gym.Space) -> Tuple[PokerExperimentParticipant]:\n",
    "    participants = []\n",
    "    for i, (agent_cls, policy_config, stack) in enumerate(agent_init_components):\n",
    "        agent_config = {'observation_space': observation_space,\n",
    "                        'action_space': action_space,\n",
    "                        'policy_config': policy_config}\n",
    "        agent = agent_cls(agent_config)\n",
    "        participants.append(PokerExperimentParticipant(id=i,\n",
    "                                                       name=f'{agent_cls.__name__}_Seat_{i + 1}',\n",
    "                                                       alias=f'Agent_{i}',\n",
    "                                                       starting_stack=stack,\n",
    "                                                       agent=agent,\n",
    "                                                       config={}))\n",
    "    return tuple(participants)\n",
    "\n",
    "# boilerplate\n",
    "@gin.configurable\n",
    "def get_prl_baseline_model_ckpt_path(path=\"\"):\n",
    "    \"\"\"Passes path from config.gin file to the caller \"\"\"\n",
    "    return path\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "def get_snowie_database_output_path(path=\"\"):\n",
    "    \"\"\"Passes path from config.gin file to the caller \"\"\"\n",
    "    return path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GIN_CONFIG_PATH'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgin\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     gin\u001B[38;5;241m.\u001B[39mparse_config_file(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menviron\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGIN_CONFIG_PATH\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m      6\u001B[0m     starting_stack_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20000\u001B[39m\n\u001B[1;32m      7\u001B[0m     sb \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n",
      "File \u001B[0;32m/usr/lib/python3.8/os.py:675\u001B[0m, in \u001B[0;36m_Environ.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    672\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencodekey(key)]\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;66;03m# raise KeyError with the original key value\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecodevalue(value)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'GIN_CONFIG_PATH'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import gin\n",
    "\n",
    "    gin.parse_config_file(os.environ['GIN_CONFIG_PATH'])\n",
    "\n",
    "    starting_stack_size = 20000\n",
    "    sb = 50\n",
    "    bb = 100\n",
    "    num_players = 6\n",
    "    max_episodes = 10\n",
    "    env = init_wrapped_env(env_wrapper_cls=AugmentObservationWrapper,\n",
    "                           stack_sizes=[starting_stack_size for _ in range(num_players)],\n",
    "                           blinds=[sb, bb],\n",
    "                           multiply_by=1)\n",
    "    # model_path = \"/home/sascha/Documents/github.com/prl_baselines/data/ckpt(1).pt\"\n",
    "    model_path = get_prl_baseline_model_ckpt_path()\n",
    "    baseline_v1 = (StakePlayerImitator,  # agent_cls\n",
    "                   {'path_to_torch_model_state_dict': model_path},  # policy_config\n",
    "                   starting_stack_size)\n",
    "    calling_station = (CallingStation,\n",
    "                       {},\n",
    "                       starting_stack_size)\n",
    "    agent_init_components = [\n",
    "        baseline_v1,  # agent_cls, policy_config, stack\n",
    "        baseline_v1,  # agent_cls, policy_config, stack\n",
    "        baseline_v1,  # agent_cls, policy_config, stack\n",
    "        baseline_v1,  # agent_cls, policy_config, stack\n",
    "        baseline_v1,  # agent_cls, policy_config, stack\n",
    "        baseline_v1  # agent_cls, policy_config, stack\n",
    "    ]\n",
    "    # todo: figure out how to ask ray.remote how many steps each actor can swing per seconds\n",
    "    # todo run with 3+ players and see if it looks reasonable -- very important\n",
    "    # todo in the baseline, if win_prob>.8 just make a bet here and there, we check way too often\n",
    "    # [x] todo button is at 3 for >3 players, not >2, fix this\n",
    "    # [x] todo player names\n",
    "\n",
    "    # todo aws rl\n",
    "    # todo very important fix the money in the experiment runnner\n",
    "\n",
    "    # todo rake -- not so important\n",
    "    # todo split pot -- we lose some games but only a very minot portion -- not important\n",
    "\n",
    "    # todo how does it perform vs callingstation in terms of bb/100\n",
    "    # todo initialize/bootstrap rl model with baseline NN\n",
    "    # todo: what do we need from the run, metrics etc?\n",
    "    # todo [optional] do we need to code up a purely MC based baseline?\n",
    "    # todo: compute Poker Stats from baesline\n",
    "    # todo: vpip 3bet etc\n",
    "    participants = make_participants(agent_init_components,\n",
    "                                     observation_space=env.observation_space,\n",
    "                                     action_space=env.action_space)\n",
    "\n",
    "    experiment = PokerExperiment(\n",
    "        # env\n",
    "        env=env,  # single environment to run sequential games on\n",
    "        num_players=num_players,\n",
    "        starting_stack_sizes=[starting_stack_size, starting_stack_size],\n",
    "        env_reset_config=None,  # can pass {'deck_state_dict': Dict[str, Any]} to init the deck and player cards\n",
    "        # run\n",
    "        max_episodes=max_episodes,  # number of games to run\n",
    "        current_episode=0,\n",
    "        cbs_plots=[],\n",
    "        cbs_misc=[],\n",
    "        cbs_metrics=[],\n",
    "        # actors\n",
    "        participants=participants,  # wrapper around agents that hold rllib policies that act given observation\n",
    "        from_action_plan=None  # compute action from fixed series of actions instead of calls to agent.act\n",
    "    )\n",
    "    db_gen = PokerExperimentToPokerSnowie().generate_database(\n",
    "        path_out=get_snowie_database_output_path(),\n",
    "        experiment=experiment,\n",
    "        max_episodes_per_file=500,\n",
    "        hero_names=[\"StakePlayerImitator_Seat_1\"]\n",
    "    )\n",
    "    # todo fix KeyError gin-path and restart for 6 players and fix offset for stack updates"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
