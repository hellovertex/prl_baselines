{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We denote by $D$ the whole dataset from `www.hhsmithy.com` consisting of 50 million played hands of NLHE.\n",
    "Let $S$ be the set of players contained in $D$. By $S(i)$ we denote the set of the top $i$ players in $S$,\n",
    "who won the most chips while having played more than 10000 played hands. There are 336 players that played more thank 10k hands.\n",
    "$S(1)$ is the player with the biggest winnings over all 50 million hands in $D$.\n",
    "\n",
    "Let $D^*(i) \\subset D$ denote the subset of $D$ containing only players in $S(i)$.\n",
    "Note that for an episode $ep \\in D^*(i)$ holds, even if no showdown player in $ep$ is a top player.\n",
    "\n",
    "On $D^*(i)$ we further define datasets in which we generate FOLD - labelled actions:\n",
    "$D^*_{F1}(i) = \\{ep \\in D^*(i): \\text{ ep has showdown player in } S(i) \\} \\cap \\{ep \\in D^*(i): \\text{ a showdown players action is labelled as FOLD if player is not in } S(i) \\}$.\n",
    "\n",
    "$D^*_{F2}(i) = \\{ep \\in D^*(i): \\text{ if a player is in } S(i) \\text{ and not in showdown players, deal them random cards} \\}$.\n",
    "todo: add \"drop all turns of players not in $S_i$.\n",
    "\n",
    "... and datasets in which we only take the actions we know from the showdown data:\n",
    "$D^*_{NF1}(i) = \\{ep \\in D^*(i): \\text{ ep has winner in } S(i) \\} \\cap \\{ep \\in D^*(i): \\text{ drop all turns of players that lost showdown} \\}$\n",
    "\n",
    "$D^*_{NF2}(i) = \\{ep \\in D^*(i): \\text{ ep has showdown player in } S(i) \\} \\cap \\{ep \\in D^*(i): \\text{ drop all turns of players not in} S(i) \\}$\n",
    "\n",
    "We train neural networks to predict the actions of a given player $p_k$ in $S(i)$ and denote it by $N_{p_k}$.\n",
    "We write $N_{p_k} | D$ to say that the network was trained on dataset $D$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given one of the datasets defined above, we can train a neural network\n",
    "i) per player\n",
    "ii) per round\n",
    "iii) per round per player\n",
    "iv) a majority voting of one of the previous"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_files_in_memory_at_once' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteTraceback\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;31mRemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/hellovertex/Documents/github.com/prl_baselines/prl/baselines/supervised_learning/v2/fast_hsmithy_parser.py\", line 510, in run_on_file\n    start = it * max_files_in_memory_at_once\nNameError: name 'max_files_in_memory_at_once' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m out_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# make dataset DF2(20)\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mmake_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43munzipped_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munzipped_dir_to_S20\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m             \u001B[49m\u001B[43mout_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m             \u001B[49m\u001B[43mselected_players\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_20\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdrop_folds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m             \u001B[49m\u001B[43monly_winners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m             \u001B[49m\u001B[43mrandomize_fold_cards\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m             \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github.com/prl_baselines/prl/baselines/supervised_learning/v2/fast_hsmithy_parser.py:600\u001B[0m, in \u001B[0;36mmake_dataset\u001B[0;34m(unzipped_dir, out_dir, selected_players, drop_folds, only_winners, randomize_fold_cards, verbose, more_than_num_players, debug)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# run f0\u001B[39;00m\n\u001B[1;32m    592\u001B[0m run_fn \u001B[38;5;241m=\u001B[39m partial(run_on_file,\n\u001B[1;32m    593\u001B[0m                  out_dir\u001B[38;5;241m=\u001B[39mout_dir,\n\u001B[1;32m    594\u001B[0m                  selected_players\u001B[38;5;241m=\u001B[39mselected_players,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    598\u001B[0m                  verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    599\u001B[0m                  more_than_num_players\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m--> 600\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m p\u001B[38;5;241m.\u001B[39mimap_unordered(run_fn, filenames):\n\u001B[1;32m    601\u001B[0m     \u001B[38;5;28mprint\u001B[39m(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    602\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinished job after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/usr/lib/python3.9/multiprocessing/pool.py:870\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[0;32m--> 870\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "\u001B[0;31mNameError\u001B[0m: name 'max_files_in_memory_at_once' is not defined"
     ]
    }
   ],
   "source": [
    "from prl.baselines.supervised_learning.v2.fast_hsmithy_parser import make_dataset\n",
    "from prl.baselines.supervised_learning.v2.config import top_100, top_20\n",
    "# todo: generate DF2(20) and train Npk as a binary predictor to predict when to fold.\n",
    "# todo: once we know when to fold (either via Npk or Nmu) we can deal with calling or bet sizing\n",
    "# todo: consider taking fold-net for all rounds but calling net for each individual p,f,t,r.\n",
    "unzipped_dir_to_S20 = \"/home/hellovertex/Documents/github.com/prl_baselines/data/01_raw/0.25-0.50/player_data_17\"\n",
    "unzipped_dir_to_S20 = \"/home/hellovertex/Documents/github.com/prl_baselines/data/01_raw/0.25-0.50/player_data_test\"\n",
    "out_dir = \"./results\"\n",
    "# make dataset DF2(20)\n",
    "make_dataset(unzipped_dir=unzipped_dir_to_S20,\n",
    "             out_dir=out_dir,\n",
    "             selected_players=top_20,\n",
    "             drop_folds=False,\n",
    "             only_winners=False,\n",
    "             randomize_fold_cards=True,\n",
    "             verbose=True,\n",
    "             debug=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
